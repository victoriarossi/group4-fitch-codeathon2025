
# Approach: One row per entity to see if any noise can be removed further
### Phase 4 — Missing Value Strategy & Clean Base Dataset

In Phase 4, we rebuilt a clean, modeling-ready base dataset with exactly one row per entity. Starting from the merged dataset, we consolidated all company-level attributes, kept the corrected environmental activity and SDG imputations, removed duplicates, and ensured that every entity had complete values for core fields such as region, country, revenue, ESG scores, and the original targets. This produced a stable, consistent dataset that aligned perfectly with the competition’s requirement for a single entity-level modeling table.

### Phase 5 — Feature Engineering
In Phase 5, we engineered all the major relational features described in the official plan. We transformed the revenue distribution table (NACE Level 2) into a wide matrix and reduced it to 10 dense PCA components representing sector exposure patterns. We also extracted environmental activity features such as the number of activities, presence of activities, and the average capped environmental adjustment per entity. In addition, we created SDG commitment features, including SDG count, SDG presence, and unique SDGs. These features were merged back into the Phase 4 dataset to produce a richer, multi-dimensional modeling dataset.

### Phase 6 — Target Transformation & Interaction Features

In Phase 6, we applied log-transformations to both target variables (target_scope_1 and target_scope_2) using log1p to stabilize variance and improve regression performance. We engineered high-value interaction features, including revenue × ESG interactions and cross-ESG interactions (E×S, S×G, E×G). Additional stability features such as revenue_log1p, ESG mean, and ESG variance were added. These transformations created more predictive signal for tree-based models and improved the dataset’s modeling quality for Phase 7.

### Phase 7 — Model Training

In Phase 7, we trained multiple baseline models following a robust and competition-aligned methodology. We created stratified K-fold splits using sector information (NACE Level 1) combined with revenue quantile buckets to ensure balanced folds. We evaluated four model types—CatBoost, XGBoost, LightGBM, and ElasticNet—on the log-transformed targets, using appropriate preprocessing for categorical and numeric features. Each model was assessed through 5-fold cross-validated RMSE, providing stable benchmarks and clear performance comparisons for later ensemble stacking.