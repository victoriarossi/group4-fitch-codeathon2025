{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üåç Comprehensive GHG Emissions Prediction Analysis\n",
        "\n",
        "This notebook follows a systematic approach to predict Scope 1 and Scope 2 greenhouse gas emissions.\n",
        "\n",
        "**Approach:**\n",
        "- Phase 1: Data Exploration & Understanding\n",
        "- Phase 2: Data Quality & Preprocessing  \n",
        "- Phase 3: Feature Engineering\n",
        "- Phase 4: Model Development\n",
        "- Phase 5: Prediction & Submission\n",
        "- Phase 6: Documentation\n",
        "\n",
        "Each step includes validation checks and explanations for why we're doing it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1: Data Exploration & Understanding\n",
        "\n",
        "### Step 1.1: Load and Inspect All Datasets\n",
        "\n",
        "**What we're doing:** Loading all CSV files and performing initial inspection\n",
        "\n",
        "**Why:**\n",
        "- Understand data structure before any transformations\n",
        "- Identify data quality issues early (missing values, duplicates, data types)\n",
        "- Check data distributions to inform feature engineering decisions\n",
        "- Verify relationships between tables (entity_id consistency)\n",
        "- Understand the scale of the problem (number of companies, features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set display options for better readability\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all datasets\n",
        "print(\"Loading datasets...\")\n",
        "train = pd.read_csv(\"../data/train.csv\")\n",
        "test = pd.read_csv(\"../data/test.csv\")\n",
        "sector = pd.read_csv(\"../data/revenue_distribution_by_sector.csv\")\n",
        "environmental = pd.read_csv(\"../data/environmental_activities.csv\")\n",
        "sdg = pd.read_csv(\"../data/sustainable_development_goals.csv\")\n",
        "\n",
        "print(\"\\n‚úÖ All datasets loaded successfully!\")\n",
        "print(f\"\\nDataset shapes:\")\n",
        "print(f\"  Train: {train.shape}\")\n",
        "print(f\"  Test: {test.shape}\")\n",
        "print(f\"  Sector: {sector.shape}\")\n",
        "print(f\"  Environmental: {environmental.shape}\")\n",
        "print(f\"  SDG: {sdg.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation Check 1: Verify Basic Data Structure\n",
        "\n",
        "**What we're checking:**\n",
        "- All files load without errors ‚úÖ\n",
        "- Check shape of each dataset (rows, columns) ‚úÖ\n",
        "- Verify entity_id is unique in train.csv and test.csv\n",
        "- Check for missing values in each column\n",
        "- Verify data types are correct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check entity_id uniqueness (CRITICAL for joins)\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDATION: Entity ID Uniqueness\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_unique = train['entity_id'].nunique()\n",
        "test_unique = test['entity_id'].nunique()\n",
        "train_total = len(train)\n",
        "test_total = len(test)\n",
        "\n",
        "print(f\"Train set: {train_total} rows, {train_unique} unique entity_ids\")\n",
        "print(f\"Test set: {test_total} rows, {test_unique} unique entity_ids\")\n",
        "\n",
        "if train_unique == train_total:\n",
        "    print(\"‚úÖ Train: All entity_ids are unique\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Train: Found {train_total - train_unique} duplicate entity_ids!\")\n",
        "\n",
        "if test_unique == test_total:\n",
        "    print(\"‚úÖ Test: All entity_ids are unique\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Test: Found {test_total - test_unique} duplicate entity_ids!\")\n",
        "\n",
        "# Check for overlap between train and test (should be NONE)\n",
        "overlap = set(train['entity_id']) & set(test['entity_id'])\n",
        "if len(overlap) == 0:\n",
        "    print(\"‚úÖ No entity_id overlap between train and test (good - no data leakage)\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  WARNING: {len(overlap)} entity_ids appear in both train and test!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDATION: Missing Values Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüìä Train.csv missing values:\")\n",
        "train_missing = train.isnull().sum()\n",
        "train_missing_pct = (train_missing / len(train) * 100).round(2)\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': train_missing,\n",
        "    'Missing %': train_missing_pct\n",
        "})\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "\n",
        "if train_missing.sum() == 0:\n",
        "    print(\"‚úÖ Train: No missing values found\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Train: Found missing values in {train_missing.sum()} cells\")\n",
        "\n",
        "print(\"\\nüìä Test.csv missing values:\")\n",
        "test_missing = test.isnull().sum()\n",
        "test_missing_pct = (test_missing / len(test) * 100).round(2)\n",
        "missing_df_test = pd.DataFrame({\n",
        "    'Missing Count': test_missing,\n",
        "    'Missing %': test_missing_pct\n",
        "})\n",
        "print(missing_df_test[missing_df_test['Missing Count'] > 0])\n",
        "\n",
        "if test_missing.sum() == 0:\n",
        "    print(\"‚úÖ Test: No missing values found\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Test: Found missing values in {test_missing.sum()} cells\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check data types and basic info\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDATION: Data Types and Basic Info\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüìä Train.csv info:\")\n",
        "print(train.info())\n",
        "print(\"\\nüìä Train.csv first few rows:\")\n",
        "print(train.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for duplicate rows\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDATION: Duplicate Rows\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_duplicates = train.duplicated().sum()\n",
        "test_duplicates = test.duplicated().sum()\n",
        "\n",
        "print(f\"Train: {train_duplicates} duplicate rows\")\n",
        "print(f\"Test: {test_duplicates} duplicate rows\")\n",
        "\n",
        "if train_duplicates == 0 and test_duplicates == 0:\n",
        "    print(\"‚úÖ No duplicate rows found\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Found duplicate rows - need to investigate!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extra Checks: Summary Statistics and Data Quality\n",
        "\n",
        "**Why:** Understanding the distribution and range of values helps us:\n",
        "- Identify outliers early\n",
        "- Decide on appropriate transformations\n",
        "- Understand the scale of the problem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics for numeric columns in train\n",
        "print(\"=\" * 60)\n",
        "print(\"SUMMARY STATISTICS: Train.csv Numeric Columns\")\n",
        "print(\"=\" * 60)\n",
        "print(train.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for negative values in key columns (shouldn't exist for revenue, emissions, scores)\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDATION: Negative Values Check\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Revenue should be positive\n",
        "negative_revenue_train = (train['revenue'] < 0).sum()\n",
        "negative_revenue_test = (test['revenue'] < 0).sum()\n",
        "\n",
        "# Targets should be non-negative\n",
        "negative_scope1 = (train['target_scope_1'] < 0).sum()\n",
        "negative_scope2 = (train['target_scope_2'] < 0).sum()\n",
        "\n",
        "# Scores should be in range 1-5\n",
        "scores_out_of_range_train = (\n",
        "    (train[['overall_score', 'environmental_score', 'social_score', 'governance_score']] < 1).any(axis=1) |\n",
        "    (train[['overall_score', 'environmental_score', 'social_score', 'governance_score']] > 5).any(axis=1)\n",
        ").sum()\n",
        "\n",
        "print(f\"Negative revenue (train): {negative_revenue_train}\")\n",
        "print(f\"Negative revenue (test): {negative_revenue_test}\")\n",
        "print(f\"Negative Scope 1 emissions: {negative_scope1}\")\n",
        "print(f\"Negative Scope 2 emissions: {negative_scope2}\")\n",
        "print(f\"Scores out of range 1-5 (train): {scores_out_of_range_train}\")\n",
        "\n",
        "if negative_revenue_train == 0 and negative_revenue_test == 0:\n",
        "    print(\"‚úÖ All revenue values are positive\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Found negative revenue values!\")\n",
        "\n",
        "if negative_scope1 == 0 and negative_scope2 == 0:\n",
        "    print(\"‚úÖ All emission values are non-negative\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Found negative emission values!\")\n",
        "\n",
        "if scores_out_of_range_train == 0:\n",
        "    print(\"‚úÖ All scores are in valid range (1-5)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Found scores outside valid range!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check categorical columns\n",
        "print(\"=\" * 60)\n",
        "print(\"CATEGORICAL COLUMNS ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüìä Region codes:\")\n",
        "print(f\"Train: {train['region_code'].value_counts()}\")\n",
        "print(f\"\\nTest: {test['region_code'].value_counts()}\")\n",
        "\n",
        "print(\"\\nüìä Country codes (top 10):\")\n",
        "print(f\"Train: {train['country_code'].value_counts().head(10)}\")\n",
        "print(f\"\\nTest: {test['country_code'].value_counts().head(10)}\")\n",
        "\n",
        "# Check if all regions in test exist in train\n",
        "train_regions = set(train['region_code'].unique())\n",
        "test_regions = set(test['region_code'].unique())\n",
        "new_regions = test_regions - train_regions\n",
        "\n",
        "if len(new_regions) == 0:\n",
        "    print(\"\\n‚úÖ All test regions exist in training data\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  New regions in test not seen in train: {new_regions}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1.2: Analyze Target Variables\n",
        "\n",
        "**What we're doing:** Deep dive into target_scope_1 and target_scope_2 distributions\n",
        "\n",
        "**Why:**\n",
        "- Emissions data is typically highly skewed (many small companies, few very large ones)\n",
        "- Understanding distribution helps decide if we need log transformation\n",
        "- Identify if there are zero-emission companies (which might need special handling)\n",
        "- Check correlation between Scope 1 and Scope 2 (they might be related)\n",
        "- Understand the range and scale of predictions needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze target variables\n",
        "print(\"=\" * 60)\n",
        "print(\"TARGET VARIABLE ANALYSIS: Scope 1 and Scope 2 Emissions\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Basic statistics\n",
        "print(\"\\nüìä Scope 1 Emissions (target_scope_1):\")\n",
        "print(train['target_scope_1'].describe())\n",
        "print(f\"\\nSkewness: {train['target_scope_1'].skew():.2f}\")\n",
        "print(f\"Kurtosis: {train['target_scope_1'].kurtosis():.2f}\")\n",
        "\n",
        "print(\"\\nüìä Scope 2 Emissions (target_scope_2):\")\n",
        "print(train['target_scope_2'].describe())\n",
        "print(f\"\\nSkewness: {train['target_scope_2'].skew():.2f}\")\n",
        "print(f\"Kurtosis: {train['target_scope_2'].kurtosis():.2f}\")\n",
        "\n",
        "# Check for zeros\n",
        "zero_scope1 = (train['target_scope_1'] == 0).sum()\n",
        "zero_scope2 = (train['target_scope_2'] == 0).sum()\n",
        "print(f\"\\nCompanies with zero Scope 1: {zero_scope1} ({zero_scope1/len(train)*100:.1f}%)\")\n",
        "print(f\"Companies with zero Scope 2: {zero_scope2} ({zero_scope2/len(train)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize target distributions\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Scope 1 histogram\n",
        "axes[0, 0].hist(train['target_scope_1'], bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_title('Scope 1 Emissions Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Scope 1 Emissions')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Scope 1 log histogram\n",
        "axes[0, 1].hist(np.log1p(train['target_scope_1']), bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
        "axes[0, 1].set_title('Log(Scope 1 + 1) Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Log(Scope 1 + 1)')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Scope 2 histogram\n",
        "axes[1, 0].hist(train['target_scope_2'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
        "axes[1, 0].set_title('Scope 2 Emissions Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Scope 2 Emissions')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Scope 2 log histogram\n",
        "axes[1, 1].hist(np.log1p(train['target_scope_2']), bins=50, edgecolor='black', alpha=0.7, color='red')\n",
        "axes[1, 1].set_title('Log(Scope 2 + 1) Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Log(Scope 2 + 1)')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° Insight: Log transformation makes distributions more normal, which can help models learn better.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check correlation between targets and with revenue\n",
        "print(\"=\" * 60)\n",
        "print(\"CORRELATION ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "correlation_matrix = train[['target_scope_1', 'target_scope_2', 'revenue']].corr()\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "scope1_scope2_corr = train['target_scope_1'].corr(train['target_scope_2'])\n",
        "scope1_revenue_corr = train['target_scope_1'].corr(train['revenue'])\n",
        "scope2_revenue_corr = train['target_scope_2'].corr(train['revenue'])\n",
        "\n",
        "print(f\"\\nüìä Key Correlations:\")\n",
        "print(f\"  Scope 1 vs Scope 2: {scope1_scope2_corr:.3f}\")\n",
        "print(f\"  Scope 1 vs Revenue: {scope1_revenue_corr:.3f}\")\n",
        "print(f\"  Scope 2 vs Revenue: {scope2_revenue_corr:.3f}\")\n",
        "\n",
        "print(\"\\nüí° Insight: Positive correlations are expected - larger companies and higher Scope 1 emissions tend to correlate with higher Scope 2 emissions.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1.3: Explore Relational Tables\n",
        "\n",
        "**What we're doing:** Analyze the 1-to-many tables (sector, environmental activities, SDGs)\n",
        "\n",
        "**Why:**\n",
        "- Understand how many sectors/activities/SDGs each company typically has\n",
        "- Identify sparse relationships (many companies might have no environmental activities)\n",
        "- Check data quality (do revenue percentages sum to ~100% per company?)\n",
        "- Understand sector distribution (which sectors are most common?)\n",
        "- Identify potential feature engineering opportunities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze sector distribution table\n",
        "print(\"=\" * 60)\n",
        "print(\"SECTOR DISTRIBUTION TABLE ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nTotal rows in sector table: {len(sector)}\")\n",
        "print(f\"Unique companies: {sector['entity_id'].nunique()}\")\n",
        "\n",
        "# Count sectors per company\n",
        "sectors_per_company = sector.groupby('entity_id').size()\n",
        "print(f\"\\nüìä Sectors per company:\")\n",
        "print(sectors_per_company.describe())\n",
        "print(f\"\\nCompanies with 1 sector: {(sectors_per_company == 1).sum()}\")\n",
        "print(f\"Companies with 2-3 sectors: {((sectors_per_company >= 2) & (sectors_per_company <= 3)).sum()}\")\n",
        "print(f\"Companies with 4+ sectors: {(sectors_per_company >= 4).sum()}\")\n",
        "\n",
        "# Check revenue percentage sums\n",
        "revenue_sums = sector.groupby('entity_id')['revenue_pct'].sum()\n",
        "print(f\"\\nüìä Revenue percentage sums per company:\")\n",
        "print(revenue_sums.describe())\n",
        "print(f\"\\nCompanies where revenue_pct sums to 100% (¬±1%): {((revenue_sums >= 99) & (revenue_sums <= 101)).sum()}\")\n",
        "print(f\"Companies with revenue_pct < 99%: {(revenue_sums < 99).sum()}\")\n",
        "print(f\"Companies with revenue_pct > 101%: {(revenue_sums > 101).sum()}\")\n",
        "\n",
        "if ((revenue_sums >= 99) & (revenue_sums <= 101)).sum() / len(revenue_sums) > 0.95:\n",
        "    print(\"‚úÖ Most companies have revenue percentages summing to ~100%\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Many companies have revenue percentages that don't sum to 100% - investigate!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze most common sectors\n",
        "print(\"\\nüìä Most common NACE Level 1 sectors:\")\n",
        "level1_counts = sector['nace_level_1_code'].value_counts()\n",
        "print(level1_counts)\n",
        "\n",
        "print(\"\\nüìä Most common NACE Level 2 sectors (top 10):\")\n",
        "level2_counts = sector['nace_level_2_code'].value_counts().head(10)\n",
        "print(level2_counts)\n",
        "\n",
        "# Check if all companies in train/test have sector data\n",
        "train_entities = set(train['entity_id'])\n",
        "test_entities = set(test['entity_id'])\n",
        "sector_entities = set(sector['entity_id'])\n",
        "\n",
        "train_with_sector = len(train_entities & sector_entities)\n",
        "test_with_sector = len(test_entities & sector_entities)\n",
        "\n",
        "print(f\"\\nüìä Sector data coverage:\")\n",
        "print(f\"Train companies with sector data: {train_with_sector}/{len(train_entities)} ({train_with_sector/len(train_entities)*100:.1f}%)\")\n",
        "print(f\"Test companies with sector data: {test_with_sector}/{len(test_entities)} ({test_with_sector/len(test_entities)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze environmental activities table\n",
        "print(\"=\" * 60)\n",
        "print(\"ENVIRONMENTAL ACTIVITIES TABLE ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nTotal rows in environmental table: {len(environmental)}\")\n",
        "print(f\"Unique companies: {environmental['entity_id'].nunique()}\")\n",
        "\n",
        "# Count activities per company\n",
        "activities_per_company = environmental.groupby('entity_id').size()\n",
        "print(f\"\\nüìä Environmental activities per company:\")\n",
        "print(activities_per_company.describe())\n",
        "\n",
        "# Check how many companies have NO environmental activities\n",
        "all_entities = set(train['entity_id']) | set(test['entity_id'])\n",
        "entities_with_activities = set(environmental['entity_id'])\n",
        "entities_without_activities = len(all_entities) - len(entities_with_activities)\n",
        "\n",
        "print(f\"\\nCompanies with environmental activities: {len(entities_with_activities)}\")\n",
        "print(f\"Companies WITHOUT environmental activities: {entities_without_activities}\")\n",
        "print(f\"Coverage: {len(entities_with_activities)/len(all_entities)*100:.1f}%\")\n",
        "\n",
        "# Analyze env_score_adjustment\n",
        "print(f\"\\nüìä Environmental score adjustment statistics:\")\n",
        "print(environmental['env_score_adjustment'].describe())\n",
        "print(f\"\\nNegative adjustments (positive activities): {(environmental['env_score_adjustment'] < 0).sum()}\")\n",
        "print(f\"Positive adjustments (negative activities): {(environmental['env_score_adjustment'] > 0).sum()}\")\n",
        "\n",
        "# Most common activity types\n",
        "print(f\"\\nüìä Most common activity types:\")\n",
        "print(environmental['activity_type'].value_counts().head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze SDG table\n",
        "print(\"=\" * 60)\n",
        "print(\"SUSTAINABLE DEVELOPMENT GOALS TABLE ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nTotal rows in SDG table: {len(sdg)}\")\n",
        "print(f\"Unique companies: {sdg['entity_id'].nunique()}\")\n",
        "\n",
        "# Count SDGs per company\n",
        "sdgs_per_company = sdg.groupby('entity_id').size()\n",
        "print(f\"\\nüìä SDGs per company:\")\n",
        "print(sdgs_per_company.describe())\n",
        "\n",
        "# Check how many companies have NO SDG commitments\n",
        "entities_with_sdg = set(sdg['entity_id'])\n",
        "entities_without_sdg = len(all_entities) - len(entities_with_sdg)\n",
        "\n",
        "print(f\"\\nCompanies with SDG commitments: {len(entities_with_sdg)}\")\n",
        "print(f\"Companies WITHOUT SDG commitments: {entities_without_sdg}\")\n",
        "print(f\"Coverage: {len(entities_with_sdg)/len(all_entities)*100:.1f}%\")\n",
        "\n",
        "# Most common SDGs\n",
        "print(f\"\\nüìä Most common SDGs:\")\n",
        "sdg_counts = sdg['sdg_id'].value_counts().sort_index()\n",
        "print(sdg_counts)\n",
        "\n",
        "# Check SDG ID range (should be 1-17)\n",
        "print(f\"\\nSDG ID range: {sdg['sdg_id'].min()} to {sdg['sdg_id'].max()}\")\n",
        "if sdg['sdg_id'].min() >= 1 and sdg['sdg_id'].max() <= 17:\n",
        "    print(\"‚úÖ All SDG IDs are in valid range (1-17)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Found SDG IDs outside valid range!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1 Summary\n",
        "\n",
        "**Key Findings:**\n",
        "1. ‚úÖ **Excellent data quality** - No missing values, no duplicates, all entity_ids unique\n",
        "2. ‚úÖ **No data leakage** - Zero overlap between train and test\n",
        "3. ‚ö†Ô∏è **Highly skewed targets** - Scope 1 (skewness: 3.15), Scope 2 (skewness: 7.34) ‚Üí **Log transformation needed**\n",
        "4. ‚úÖ **Sparse relational tables** - Environmental activities and SDGs are sparse (expected)\n",
        "5. ‚úÖ **All test regions exist in training** - No cold start problem\n",
        "6. ‚úÖ **Ready for feature engineering** - Clean data structure\n",
        "\n",
        "**Key Insights:**\n",
        "- Both target variables are highly right-skewed ‚Üí log transformation will significantly help models\n",
        "- 13 companies (3%) have zero Scope 2 emissions (legitimate - may not purchase electricity)\n",
        "- Sector data is rich and will be a strong predictor\n",
        "- Geographic distribution is balanced (WEU and NAM dominate)\n",
        "\n",
        "**Next Steps:** Proceed to Phase 2: Data Quality & Preprocessing (quick validation), then Phase 3: Feature Engineering\n",
        "\n",
        "---\n",
        "\n",
        "## Phase 2: Data Quality & Preprocessing\n",
        "\n",
        "**Note:** Phase 1 revealed excellent data quality with no missing values. Phase 2 will perform final validation checks before feature engineering.\n",
        "\n",
        "### Step 2.1: Final Data Quality Validation\n",
        "\n",
        "**What we're doing:** Final checks to ensure data is ready for feature engineering\n",
        "\n",
        "**Why:**\n",
        "- Double-check everything before transformations\n",
        "- Ensure train and test distributions are similar\n",
        "- Verify no issues that could cause problems later\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final validation: Compare train and test distributions\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 2: FINAL DATA QUALITY VALIDATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüìä Train vs Test Distribution Comparison:\")\n",
        "print(f\"\\nRevenue statistics:\")\n",
        "print(f\"  Train - Mean: {train['revenue'].mean():.2f}, Median: {train['revenue'].median():.2f}\")\n",
        "print(f\"  Test  - Mean: {test['revenue'].mean():.2f}, Median: {test['revenue'].median():.2f}\")\n",
        "\n",
        "print(f\"\\nSustainability scores (train vs test):\")\n",
        "for score in ['overall_score', 'environmental_score', 'social_score', 'governance_score']:\n",
        "    train_mean = train[score].mean()\n",
        "    test_mean = test[score].mean()\n",
        "    diff = abs(train_mean - test_mean)\n",
        "    status = \"‚úÖ\" if diff < 0.5 else \"‚ö†Ô∏è\"\n",
        "    print(f\"  {score}: Train={train_mean:.2f}, Test={test_mean:.2f}, Diff={diff:.2f} {status}\")\n",
        "\n",
        "print(\"\\n‚úÖ Phase 2 Complete: Data quality validated, ready for feature engineering!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 3: Feature Engineering\n",
        "\n",
        "This is the **most important phase** - creating meaningful features from the raw data.\n",
        "\n",
        "### Step 3.1: Geographic Features\n",
        "\n",
        "**What we're doing:** Encode geographic information (region, country)\n",
        "\n",
        "**Why:**\n",
        "- Different regions have different energy grid carbon intensity (affects Scope 2)\n",
        "- Different environmental regulations (affects both scopes)\n",
        "- One-hot encoding allows models to learn region-specific patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create copies for feature engineering (preserve originals)\n",
        "train_fe = train.copy()\n",
        "test_fe = test.copy()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 3: FEATURE ENGINEERING\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nStarting with {len(train_fe)} train and {len(test_fe)} test companies\")\n",
        "\n",
        "# Step 3.1: Geographic Features - One-hot encode region_code\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 3.1: Geographic Features\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# One-hot encode region_code\n",
        "train_fe = pd.get_dummies(train_fe, columns=['region_code'], prefix='region')\n",
        "test_fe = pd.get_dummies(test_fe, columns=['region_code'], prefix='region')\n",
        "\n",
        "# Ensure test has same region columns as train (add missing with 0s)\n",
        "for col in train_fe.columns:\n",
        "    if col.startswith('region_') and col not in test_fe.columns:\n",
        "        test_fe[col] = 0\n",
        "\n",
        "# Ensure train has same region columns as test (add missing with 0s)\n",
        "for col in test_fe.columns:\n",
        "    if col.startswith('region_') and col not in train_fe.columns:\n",
        "        train_fe[col] = 0\n",
        "\n",
        "# Reorder columns to match\n",
        "region_cols = sorted([col for col in train_fe.columns if col.startswith('region_')])\n",
        "print(f\"\\n‚úÖ Created {len(region_cols)} region features:\")\n",
        "print(f\"   {region_cols}\")\n",
        "\n",
        "print(f\"\\nTrain shape: {train_fe.shape}\")\n",
        "print(f\"Test shape: {test_fe.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.2: Sector Distribution Features (NACE Level 1)\n",
        "\n",
        "**What we're doing:** Aggregate sector revenue percentages to entity level\n",
        "\n",
        "**Why:**\n",
        "- Different sectors have vastly different emission intensities\n",
        "- Manufacturing (high Scope 1) vs Services (low Scope 1, moderate Scope 2)\n",
        "- Revenue percentage indicates how much of company's operations are in each sector\n",
        "- Pivoting creates one row per company with sector exposure percentages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3.2: Sector Features - NACE Level 1\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 3.2: Sector Distribution Features (NACE Level 1)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Pivot sector data to entity level\n",
        "level_1_sect = sector.pivot_table(\n",
        "    values='revenue_pct',\n",
        "    index='entity_id',\n",
        "    columns='nace_level_1_code',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0\n",
        ").add_prefix('sect_').add_suffix('_pct').reset_index()\n",
        "\n",
        "print(f\"\\nCreated sector features for {len(level_1_sect)} companies\")\n",
        "print(f\"Sector columns: {list(level_1_sect.columns[1:])}\")  # Exclude entity_id\n",
        "\n",
        "# Join to train and test\n",
        "train_fe = train_fe.merge(level_1_sect, on='entity_id', how='left')\n",
        "test_fe = test_fe.merge(level_1_sect, on='entity_id', how='left')\n",
        "\n",
        "# Fill missing sector percentages with 0 (company has 0% in that sector)\n",
        "sect_cols = [col for col in level_1_sect.columns if col != 'entity_id']\n",
        "train_fe[sect_cols] = train_fe[sect_cols].fillna(0)\n",
        "test_fe[sect_cols] = test_fe[sect_cols].fillna(0)\n",
        "\n",
        "print(f\"\\n‚úÖ Created {len(sect_cols)} sector features\")\n",
        "print(f\"Train shape: {train_fe.shape}\")\n",
        "print(f\"Test shape: {test_fe.shape}\")\n",
        "\n",
        "# Validation: Check revenue percentages sum to ~100%\n",
        "revenue_sums = train_fe[sect_cols].sum(axis=1)\n",
        "print(f\"\\nüìä Revenue percentage validation:\")\n",
        "print(f\"  Mean sum: {revenue_sums.mean():.1f}%\")\n",
        "print(f\"  Companies with sum 99-101%: {((revenue_sums >= 99) & (revenue_sums <= 101)).sum()}/{len(train_fe)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.3: Sector Diversity Features\n",
        "\n",
        "**What we're doing:** Create metrics describing how diversified a company's sector exposure is\n",
        "\n",
        "**Why:**\n",
        "- Diversified companies might have different emission profiles than focused ones\n",
        "- Sector concentration (Herfindahl index) measures diversification\n",
        "- Number of sectors indicates complexity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3.3: Sector Diversity Features\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 3.3: Sector Diversity Features\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Count number of sectors per company (revenue_pct > 0)\n",
        "train_fe['num_sectors'] = (train_fe[sect_cols] > 0).sum(axis=1)\n",
        "test_fe['num_sectors'] = (test_fe[sect_cols] > 0).sum(axis=1)\n",
        "\n",
        "# Calculate Herfindahl-Hirschman Index (HHI) for sector concentration\n",
        "# HHI = sum of squared revenue percentages (0-1 scale, higher = more concentrated)\n",
        "train_fe['sector_hhi'] = (train_fe[sect_cols] / 100).pow(2).sum(axis=1)\n",
        "test_fe['sector_hhi'] = (test_fe[sect_cols] / 100).pow(2).sum(axis=1)\n",
        "\n",
        "# Find dominant sector (highest revenue percentage)\n",
        "train_fe['dominant_sector_pct'] = train_fe[sect_cols].max(axis=1)\n",
        "test_fe['dominant_sector_pct'] = test_fe[sect_cols].max(axis=1)\n",
        "\n",
        "# Binary: is company diversified (more than 1 sector)\n",
        "train_fe['is_diversified'] = (train_fe['num_sectors'] > 1).astype(int)\n",
        "test_fe['is_diversified'] = (test_fe['num_sectors'] > 1).astype(int)\n",
        "\n",
        "print(f\"\\n‚úÖ Created sector diversity features:\")\n",
        "print(f\"   - num_sectors: Number of sectors per company\")\n",
        "print(f\"   - sector_hhi: Herfindahl-Hirschman Index (concentration)\")\n",
        "print(f\"   - dominant_sector_pct: Percentage of revenue from dominant sector\")\n",
        "print(f\"   - is_diversified: Binary indicator (1 if >1 sector)\")\n",
        "\n",
        "print(f\"\\nSector diversity statistics:\")\n",
        "print(f\"  Mean sectors per company: {train_fe['num_sectors'].mean():.2f}\")\n",
        "print(f\"  Diversified companies: {train_fe['is_diversified'].sum()}/{len(train_fe)} ({train_fe['is_diversified'].mean()*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.4: Environmental Activity Features\n",
        "\n",
        "**What we're doing:** Aggregate environmental activity data to entity level\n",
        "\n",
        "**Why:**\n",
        "- Environmental activities indicate company's environmental focus\n",
        "- Positive activities (negative env_score_adjustment) might correlate with lower emissions\n",
        "- Sum of adjustments gives overall environmental impact score\n",
        "- Count of activities indicates engagement level\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3.4: Environmental Activity Features\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 3.4: Environmental Activity Features\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Aggregate environmental activities\n",
        "env_features = environmental.groupby('entity_id').agg({\n",
        "    'env_score_adjustment': ['sum', 'count']\n",
        "}).reset_index()\n",
        "env_features.columns = ['entity_id', 'env_score_adjustment_sum', 'num_env_activities']\n",
        "\n",
        "# Separate positive and negative adjustments\n",
        "env_pos = environmental[environmental['env_score_adjustment'] > 0].groupby('entity_id')['env_score_adjustment'].sum().reset_index()\n",
        "env_pos.columns = ['entity_id', 'env_positive_adjustment']\n",
        "env_neg = environmental[environmental['env_score_adjustment'] < 0].groupby('entity_id')['env_score_adjustment'].sum().reset_index()\n",
        "env_neg.columns = ['entity_id', 'env_negative_adjustment']\n",
        "\n",
        "# Join all environmental features\n",
        "env_features = env_features.merge(env_pos, on='entity_id', how='left')\n",
        "env_features = env_features.merge(env_neg, on='entity_id', how='left')\n",
        "\n",
        "# Join to train and test (left join to preserve all companies)\n",
        "train_fe = train_fe.merge(env_features, on='entity_id', how='left')\n",
        "test_fe = test_fe.merge(env_features, on='entity_id', how='left')\n",
        "\n",
        "# Fill missing with 0 (no environmental activities)\n",
        "env_cols = ['env_score_adjustment_sum', 'num_env_activities', 'env_positive_adjustment', 'env_negative_adjustment']\n",
        "train_fe[env_cols] = train_fe[env_cols].fillna(0)\n",
        "test_fe[env_cols] = test_fe[env_cols].fillna(0)\n",
        "\n",
        "# Create binary indicator\n",
        "train_fe['has_env_activities'] = (train_fe['num_env_activities'] > 0).astype(int)\n",
        "test_fe['has_env_activities'] = (test_fe['num_env_activities'] > 0).astype(int)\n",
        "\n",
        "print(f\"\\n‚úÖ Created environmental activity features:\")\n",
        "print(f\"   - env_score_adjustment_sum: Total environmental score adjustment\")\n",
        "print(f\"   - num_env_activities: Count of environmental activities\")\n",
        "print(f\"   - env_positive_adjustment: Sum of positive adjustments (bad activities)\")\n",
        "print(f\"   - env_negative_adjustment: Sum of negative adjustments (good activities)\")\n",
        "print(f\"   - has_env_activities: Binary indicator\")\n",
        "\n",
        "print(f\"\\nEnvironmental activity statistics:\")\n",
        "print(f\"  Companies with activities: {train_fe['has_env_activities'].sum()}/{len(train_fe)} ({train_fe['has_env_activities'].mean()*100:.1f}%)\")\n",
        "print(f\"  Mean activities per company: {train_fe['num_env_activities'].mean():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.5: SDG Commitment Features\n",
        "\n",
        "**What we're doing:** Encode SDG commitments as features\n",
        "\n",
        "**Why:**\n",
        "- SDG commitments indicate sustainability focus\n",
        "- Different SDGs relate differently to emissions (SDG 7, 13 are directly related)\n",
        "- Count of SDGs indicates commitment level\n",
        "- Presence/absence of specific SDGs might be predictive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3.5: SDG Commitment Features\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 3.5: SDG Commitment Features\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# One-hot encode SDG IDs\n",
        "sdg_encoded = pd.get_dummies(sdg[['entity_id', 'sdg_id']], columns=['sdg_id'], prefix='sdg')\n",
        "sdg_encoded = sdg_encoded.groupby('entity_id').sum().reset_index()\n",
        "\n",
        "# Count total SDGs per company\n",
        "sdg_count = sdg.groupby('entity_id').size().reset_index(name='num_sdgs')\n",
        "\n",
        "# Create specific SDG indicators (SDG 7: Clean Energy, SDG 13: Climate Action)\n",
        "sdg_7_13 = sdg[sdg['sdg_id'].isin([7, 13])].groupby('entity_id')['sdg_id'].apply(lambda x: 1 if 7 in x.values else (2 if 13 in x.values else 0)).reset_index()\n",
        "sdg_7_13.columns = ['entity_id', 'has_sdg_7_or_13']\n",
        "sdg_7_13['has_sdg_7_or_13'] = (sdg_7_13['has_sdg_7_or_13'] > 0).astype(int)\n",
        "\n",
        "# Combine SDG features\n",
        "sdg_features = sdg_encoded.merge(sdg_count, on='entity_id', how='left')\n",
        "sdg_features = sdg_features.merge(sdg_7_13, on='entity_id', how='left')\n",
        "sdg_features['num_sdgs'] = sdg_features['num_sdgs'].fillna(0)\n",
        "sdg_features['has_sdg_7_or_13'] = sdg_features['has_sdg_7_or_13'].fillna(0)\n",
        "\n",
        "# Join to train and test (left join)\n",
        "train_fe = train_fe.merge(sdg_features, on='entity_id', how='left')\n",
        "test_fe = test_fe.merge(sdg_features, on='entity_id', how='left')\n",
        "\n",
        "# Fill missing SDG columns with 0\n",
        "sdg_cols = [col for col in sdg_features.columns if col != 'entity_id']\n",
        "train_fe[sdg_cols] = train_fe[sdg_cols].fillna(0)\n",
        "test_fe[sdg_cols] = test_fe[sdg_cols].fillna(0)\n",
        "\n",
        "# Ensure test has same SDG columns as train\n",
        "for col in train_fe.columns:\n",
        "    if col.startswith('sdg_') and col not in test_fe.columns:\n",
        "        test_fe[col] = 0\n",
        "\n",
        "# Create binary indicator\n",
        "train_fe['has_sdgs'] = (train_fe['num_sdgs'] > 0).astype(int)\n",
        "test_fe['has_sdgs'] = (test_fe['num_sdgs'] > 0).astype(int)\n",
        "\n",
        "print(f\"\\n‚úÖ Created SDG commitment features:\")\n",
        "print(f\"   - num_sdgs: Total number of SDG commitments\")\n",
        "print(f\"   - has_sdg_7_or_13: Binary for SDG 7 (Clean Energy) or SDG 13 (Climate Action)\")\n",
        "print(f\"   - has_sdgs: Binary indicator for any SDG commitment\")\n",
        "print(f\"   - sdg_X: One-hot encoded SDG IDs\")\n",
        "\n",
        "print(f\"\\nSDG commitment statistics:\")\n",
        "print(f\"  Companies with SDGs: {train_fe['has_sdgs'].sum()}/{len(train_fe)} ({train_fe['has_sdgs'].mean()*100:.1f}%)\")\n",
        "print(f\"  Mean SDGs per company: {train_fe['num_sdgs'].mean():.2f}\")\n",
        "print(f\"  Companies with SDG 7 or 13: {train_fe['has_sdg_7_or_13'].sum()}/{len(train_fe)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.6: Revenue-Based Features\n",
        "\n",
        "**What we're doing:** Create features derived from revenue\n",
        "\n",
        "**Why:**\n",
        "- Revenue is a strong proxy for company size\n",
        "- Larger companies typically have higher absolute emissions\n",
        "- But emissions per revenue unit (intensity) varies by sector\n",
        "- Log transformation helps with skewed distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3.6: Revenue-Based Features\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 3.6: Revenue-Based Features\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Log transform revenue (handle skewed distribution)\n",
        "train_fe['log_revenue'] = np.log1p(train_fe['revenue'])  # log1p = log(1+x) handles zeros\n",
        "test_fe['log_revenue'] = np.log1p(test_fe['revenue'])\n",
        "\n",
        "# Revenue categories (optional - for non-linear relationships)\n",
        "train_fe['revenue_category'] = pd.cut(train_fe['revenue'], \n",
        "                                      bins=[0, 1e8, 1e9, 1e10, np.inf],\n",
        "                                      labels=['Small', 'Medium', 'Large', 'Very Large'])\n",
        "test_fe['revenue_category'] = pd.cut(test_fe['revenue'],\n",
        "                                     bins=[0, 1e8, 1e9, 1e10, np.inf],\n",
        "                                     labels=['Small', 'Medium', 'Large', 'Very Large'])\n",
        "\n",
        "# One-hot encode revenue category\n",
        "train_fe = pd.get_dummies(train_fe, columns=['revenue_category'], prefix='revenue_cat')\n",
        "test_fe = pd.get_dummies(test_fe, columns=['revenue_category'], prefix='revenue_cat')\n",
        "\n",
        "# Ensure test has same revenue category columns\n",
        "for col in train_fe.columns:\n",
        "    if col.startswith('revenue_cat_') and col not in test_fe.columns:\n",
        "        test_fe[col] = 0\n",
        "\n",
        "print(f\"\\n‚úÖ Created revenue-based features:\")\n",
        "print(f\"   - log_revenue: Log-transformed revenue (handles skewness)\")\n",
        "print(f\"   - revenue_cat_X: Revenue category (Small, Medium, Large, Very Large)\")\n",
        "\n",
        "print(f\"\\nRevenue statistics:\")\n",
        "print(f\"  Original revenue - Mean: {train_fe['revenue'].mean():.2e}, Median: {train_fe['revenue'].median():.2e}\")\n",
        "print(f\"  Log revenue - Mean: {train_fe['log_revenue'].mean():.2f}, Median: {train_fe['log_revenue'].median():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.7: Interaction Features\n",
        "\n",
        "**What we're doing:** Create features that combine multiple base features\n",
        "\n",
        "**Why:**\n",
        "- Interactions capture complex relationships\n",
        "- Revenue √ó sector: different sectors scale differently with size\n",
        "- Region √ó sector: same sector might have different emissions in different regions\n",
        "- Score √ó revenue: environmental focus might matter more for larger companies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3.7: Interaction Features\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 3.7: Interaction Features\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Revenue √ó dominant sector percentage\n",
        "train_fe['revenue_x_dominant_sector'] = train_fe['revenue'] * train_fe['dominant_sector_pct'] / 100\n",
        "test_fe['revenue_x_dominant_sector'] = test_fe['revenue'] * test_fe['dominant_sector_pct'] / 100\n",
        "\n",
        "# Revenue √ó environmental score\n",
        "train_fe['revenue_x_env_score'] = train_fe['revenue'] * train_fe['environmental_score']\n",
        "test_fe['revenue_x_env_score'] = test_fe['revenue'] * test_fe['environmental_score']\n",
        "\n",
        "# Log revenue √ó environmental score\n",
        "train_fe['log_revenue_x_env_score'] = train_fe['log_revenue'] * train_fe['environmental_score']\n",
        "test_fe['log_revenue_x_env_score'] = test_fe['log_revenue'] * test_fe['environmental_score']\n",
        "\n",
        "# Revenue √ó sector diversity\n",
        "train_fe['revenue_x_diversity'] = train_fe['revenue'] * train_fe['num_sectors']\n",
        "test_fe['revenue_x_diversity'] = test_fe['revenue'] * test_fe['num_sectors']\n",
        "\n",
        "print(f\"\\n‚úÖ Created interaction features:\")\n",
        "print(f\"   - revenue_x_dominant_sector: Revenue √ó dominant sector percentage\")\n",
        "print(f\"   - revenue_x_env_score: Revenue √ó environmental score\")\n",
        "print(f\"   - log_revenue_x_env_score: Log revenue √ó environmental score\")\n",
        "print(f\"   - revenue_x_diversity: Revenue √ó number of sectors\")\n",
        "\n",
        "print(f\"\\nFeature engineering complete!\")\n",
        "print(f\"Final train shape: {train_fe.shape}\")\n",
        "print(f\"Final test shape: {test_fe.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.8: Feature Selection\n",
        "\n",
        "**What we're doing:** Remove low-variance or uninformative features\n",
        "\n",
        "**Why:**\n",
        "- Too many features can lead to overfitting\n",
        "- Low-variance features provide little information\n",
        "- Reduces model complexity and training time\n",
        "- Improves generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3.8: Feature Selection\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 3.8: Feature Selection\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Exclude non-feature columns\n",
        "cols_to_exclude = ['entity_id', 'region_name', 'country_name', 'country_code', \n",
        "                   'target_scope_1', 'target_scope_2']\n",
        "feature_cols = [col for col in train_fe.columns if col not in cols_to_exclude]\n",
        "\n",
        "# Apply variance threshold (remove near-constant features)\n",
        "feature_selector = VarianceThreshold(threshold=0.01)  # Keep features with variance > 0.01\n",
        "feature_selector.fit(train_fe[feature_cols])\n",
        "\n",
        "selected_features = feature_selector.get_feature_names_out().tolist()\n",
        "removed_features = [col for col in feature_cols if col not in selected_features]\n",
        "\n",
        "print(f\"\\nüìä Feature selection results:\")\n",
        "print(f\"  Original features: {len(feature_cols)}\")\n",
        "print(f\"  Selected features: {len(selected_features)}\")\n",
        "print(f\"  Removed features: {len(removed_features)}\")\n",
        "\n",
        "if removed_features:\n",
        "    print(f\"\\n  Removed features: {removed_features[:10]}...\")  # Show first 10\n",
        "\n",
        "# Create final datasets with selected features\n",
        "final_train = train_fe[selected_features + ['entity_id', 'target_scope_1', 'target_scope_2']].copy()\n",
        "final_test = test_fe[selected_features + ['entity_id']].copy()\n",
        "\n",
        "print(f\"\\n‚úÖ Final datasets created:\")\n",
        "print(f\"  Train: {final_train.shape}\")\n",
        "print(f\"  Test: {final_test.shape}\")\n",
        "\n",
        "# Save for next phase\n",
        "import os\n",
        "save_dir = 'notebooks' if os.path.exists('notebooks') else '.'\n",
        "final_train.to_pickle(f'{save_dir}/final_train_fe.pkl')\n",
        "final_test.to_pickle(f'{save_dir}/final_test_fe.pkl')\n",
        "\n",
        "print(f\"\\n‚úÖ Feature engineering complete! Datasets saved.\")\n",
        "print(f\"   Ready for Phase 4: Model Development\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 4: Model Development\n",
        "\n",
        "This phase will train and evaluate models to predict Scope 1 and Scope 2 emissions.\n",
        "\n",
        "### Step 4.1: Prepare Training Data\n",
        "\n",
        "**What we're doing:** Load feature-engineered data and prepare for modeling\n",
        "\n",
        "**Why:**\n",
        "- Separate features (X) from targets (y)\n",
        "- Apply log transformation to targets (they're highly skewed)\n",
        "- Ensure train and test have same features\n",
        "- Final validation before training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4.1: Prepare Training Data\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 4: MODEL DEVELOPMENT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load feature-engineered datasets\n",
        "import os\n",
        "load_path = 'notebooks/final_train_fe.pkl' if os.path.exists('notebooks/final_train_fe.pkl') else 'final_train_fe.pkl'\n",
        "train_model = pd.read_pickle(load_path)\n",
        "test_model = pd.read_pickle(load_path.replace('train', 'test'))\n",
        "\n",
        "print(f\"\\n‚úÖ Loaded feature-engineered datasets:\")\n",
        "print(f\"  Train: {train_model.shape}\")\n",
        "print(f\"  Test: {test_model.shape}\")\n",
        "\n",
        "# Separate features and targets\n",
        "X_train = train_model.drop(columns=['entity_id', 'target_scope_1', 'target_scope_2'])\n",
        "y_scope1 = train_model['target_scope_1']\n",
        "y_scope2 = train_model['target_scope_2']\n",
        "X_test = test_model.drop(columns=['entity_id'])\n",
        "entity_ids_test = test_model['entity_id']\n",
        "\n",
        "print(f\"\\nüìä Data preparation:\")\n",
        "print(f\"  Features (X_train): {X_train.shape}\")\n",
        "print(f\"  Scope 1 target: {y_scope1.shape}\")\n",
        "print(f\"  Scope 2 target: {y_scope2.shape}\")\n",
        "print(f\"  Test features: {X_test.shape}\")\n",
        "\n",
        "# Apply log transformation to targets (they're highly skewed)\n",
        "y_scope1_log = np.log1p(y_scope1)  # log1p = log(1+x) handles zeros\n",
        "y_scope2_log = np.log1p(y_scope2)\n",
        "\n",
        "print(f\"\\n‚úÖ Applied log transformation to targets:\")\n",
        "print(f\"  Scope 1 - Original skewness: {y_scope1.skew():.2f}, Log skewness: {y_scope1_log.skew():.2f}\")\n",
        "print(f\"  Scope 2 - Original skewness: {y_scope2.skew():.2f}, Log skewness: {y_scope2_log.skew():.2f}\")\n",
        "\n",
        "# Verify no missing values\n",
        "print(f\"\\nüìä Data quality check:\")\n",
        "print(f\"  Missing values in X_train: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"  Missing values in X_test: {X_test.isnull().sum().sum()}\")\n",
        "print(f\"  Infinite values in X_train: {np.isinf(X_train.select_dtypes(include=[np.number])).sum().sum()}\")\n",
        "print(f\"  Infinite values in targets: {np.isinf(y_scope1_log).sum() + np.isinf(y_scope2_log).sum()}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Data ready for model training!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4.2: Train-Validation Split\n",
        "\n",
        "**What we're doing:** Split training data for validation\n",
        "\n",
        "**Why:**\n",
        "- Need to evaluate model performance without using test set\n",
        "- Prevents overfitting\n",
        "- Allows hyperparameter tuning\n",
        "- K-fold CV provides more robust performance estimate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4.2: Train-Validation Split\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 4.2: Train-Validation Split\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split for validation (80/20)\n",
        "X_train_split, X_val_split, y_s1_train, y_s1_val = train_test_split(\n",
        "    X_train, y_scope1_log, test_size=0.2, random_state=42\n",
        ")\n",
        "_, _, y_s2_train, y_s2_val = train_test_split(\n",
        "    X_train, y_scope2_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Train-validation split:\")\n",
        "print(f\"  Training set: {X_train_split.shape[0]} samples\")\n",
        "print(f\"  Validation set: {X_val_split.shape[0]} samples\")\n",
        "print(f\"  Split ratio: 80/20\")\n",
        "\n",
        "print(f\"\\n‚úÖ Ready for model training and validation!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4.3: Baseline Model Training\n",
        "\n",
        "**What we're doing:** Train simple baseline models (Linear Regression, Random Forest)\n",
        "\n",
        "**Why:**\n",
        "- Establishes performance baseline\n",
        "- Linear model: fast, interpretable, good for understanding relationships\n",
        "- Random Forest: handles non-linearities, feature interactions automatically\n",
        "- Compare to see which approach works better\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4.3: Baseline Model Training\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 4.3: Baseline Model Training\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(y_true, y_pred, model_name, target_name):\n",
        "    \"\"\"Evaluate model and return metrics\"\"\"\n",
        "    # Convert back from log space\n",
        "    y_true_orig = np.expm1(y_true)\n",
        "    y_pred_orig = np.expm1(y_pred)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    rmse = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
        "    mae = mean_absolute_error(y_true_orig, y_pred_orig)\n",
        "    r2 = r2_score(y_true_orig, y_pred_orig)\n",
        "    \n",
        "    print(f\"\\nüìä {model_name} - {target_name} Performance:\")\n",
        "    print(f\"  RMSE: {rmse:,.2f}\")\n",
        "    print(f\"  MAE: {mae:,.2f}\")\n",
        "    print(f\"  R¬≤: {r2:.4f}\")\n",
        "    \n",
        "    return {'rmse': rmse, 'mae': mae, 'r2': r2}\n",
        "\n",
        "# Train Linear Regression models\n",
        "print(\"\\nüîµ Training Linear Regression models...\")\n",
        "\n",
        "# Scope 1\n",
        "lr_s1 = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "lr_s1.fit(X_train_split, y_s1_train)\n",
        "y_s1_pred_lr = lr_s1.predict(X_val_split)\n",
        "lr_s1_metrics = evaluate_model(y_s1_val, y_s1_pred_lr, \"Linear Regression\", \"Scope 1\")\n",
        "\n",
        "# Scope 2\n",
        "lr_s2 = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "lr_s2.fit(X_train_split, y_s2_train)\n",
        "y_s2_pred_lr = lr_s2.predict(X_val_split)\n",
        "lr_s2_metrics = evaluate_model(y_s2_val, y_s2_pred_lr, \"Linear Regression\", \"Scope 2\")\n",
        "\n",
        "# Train Random Forest models\n",
        "print(\"\\nüü¢ Training Random Forest models...\")\n",
        "\n",
        "# Scope 1\n",
        "rf_s1 = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf_s1.fit(X_train_split, y_s1_train)\n",
        "y_s1_pred_rf = rf_s1.predict(X_val_split)\n",
        "rf_s1_metrics = evaluate_model(y_s1_val, y_s1_pred_rf, \"Random Forest\", \"Scope 1\")\n",
        "\n",
        "# Scope 2\n",
        "rf_s2 = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf_s2.fit(X_train_split, y_s2_train)\n",
        "y_s2_pred_rf = rf_s2.predict(X_val_split)\n",
        "rf_s2_metrics = evaluate_model(y_s2_val, y_s2_pred_rf, \"Random Forest\", \"Scope 2\")\n",
        "\n",
        "# Train Boosting Models (Gradient Boosting - built into sklearn, no external deps)\n",
        "print(\"\\nüü° Training Boosting Models (Gradient Boosting)...\")\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Scope 1\n",
        "gb_s1 = GradientBoostingRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    random_state=42,\n",
        "    validation_fraction=0.2,\n",
        "    n_iter_no_change=10,\n",
        "    tol=1e-4\n",
        ")\n",
        "gb_s1.fit(X_train_split, y_s1_train)\n",
        "y_s1_pred_gb = gb_s1.predict(X_val_split)\n",
        "gb_s1_metrics = evaluate_model(y_s1_val, y_s1_pred_gb, \"Gradient Boosting\", \"Scope 1\")\n",
        "\n",
        "# Scope 2\n",
        "gb_s2 = GradientBoostingRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    random_state=42,\n",
        "    validation_fraction=0.2,\n",
        "    n_iter_no_change=10,\n",
        "    tol=1e-4\n",
        ")\n",
        "gb_s2.fit(X_train_split, y_s2_train)\n",
        "y_s2_pred_gb = gb_s2.predict(X_val_split)\n",
        "gb_s2_metrics = evaluate_model(y_s2_val, y_s2_pred_gb, \"Gradient Boosting\", \"Scope 2\")\n",
        "\n",
        "gb_available = True\n",
        "print(\"\\n‚úÖ Gradient Boosting models trained and evaluated!\")\n",
        "\n",
        "print(\"\\n‚úÖ All models trained and evaluated!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4.4: Cross-Validation Evaluation\n",
        "\n",
        "**What we're doing:** Use K-fold cross-validation for more robust performance estimates\n",
        "\n",
        "**Why:**\n",
        "- Single train/validation split can be biased\n",
        "- K-fold CV gives more reliable performance estimate\n",
        "- Better for comparing models\n",
        "- Reduces variance in performance estimates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4.4: Cross-Validation Evaluation\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 4.4: Cross-Validation Evaluation\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "def cv_evaluate_model(model, X, y, model_name, target_name, cv_folds=5):\n",
        "    \"\"\"Evaluate model using cross-validation\"\"\"\n",
        "    kfold = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "    \n",
        "    # Perform cross-validation (using negative MSE, convert to RMSE)\n",
        "    cv_scores = cross_val_score(\n",
        "        model, X, y, \n",
        "        cv=kfold, \n",
        "        scoring='neg_mean_squared_error',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    # Convert to RMSE (positive values)\n",
        "    rmse_scores = np.sqrt(-cv_scores)\n",
        "    \n",
        "    print(f\"\\nüìä {model_name} - {target_name} (CV):\")\n",
        "    print(f\"  RMSE scores: {rmse_scores}\")\n",
        "    print(f\"  Mean RMSE: {rmse_scores.mean():,.2f}\")\n",
        "    print(f\"  Std RMSE: {rmse_scores.std():,.2f}\")\n",
        "    \n",
        "    return rmse_scores.mean(), rmse_scores.std()\n",
        "\n",
        "# Evaluate Linear Regression with CV\n",
        "print(\"\\nüîµ Linear Regression Cross-Validation:\")\n",
        "lr_s1_cv_mean, lr_s1_cv_std = cv_evaluate_model(\n",
        "    lr_s1, X_train, y_scope1_log, \"Linear Regression\", \"Scope 1\"\n",
        ")\n",
        "lr_s2_cv_mean, lr_s2_cv_std = cv_evaluate_model(\n",
        "    lr_s2, X_train, y_scope2_log, \"Linear Regression\", \"Scope 2\"\n",
        ")\n",
        "\n",
        "# Evaluate Random Forest with CV\n",
        "print(\"\\nüü¢ Random Forest Cross-Validation:\")\n",
        "rf_s1_cv_mean, rf_s1_cv_std = cv_evaluate_model(\n",
        "    rf_s1, X_train, y_scope1_log, \"Random Forest\", \"Scope 1\"\n",
        ")\n",
        "rf_s2_cv_mean, rf_s2_cv_std = cv_evaluate_model(\n",
        "    rf_s2, X_train, y_scope2_log, \"Random Forest\", \"Scope 2\"\n",
        ")\n",
        "\n",
        "# Evaluate Gradient Boosting with CV\n",
        "if 'gb_available' in locals() and gb_available:\n",
        "    print(\"\\nüü° Gradient Boosting Cross-Validation:\")\n",
        "    gb_s1_cv_mean, gb_s1_cv_std = cv_evaluate_model(\n",
        "        gb_s1, X_train, y_scope1_log, \"Gradient Boosting\", \"Scope 1\"\n",
        "    )\n",
        "    gb_s2_cv_mean, gb_s2_cv_std = cv_evaluate_model(\n",
        "        gb_s2, X_train, y_scope2_log, \"Gradient Boosting\", \"Scope 2\"\n",
        "    )\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Gradient Boosting not available for cross-validation\")\n",
        "    gb_s1_cv_mean, gb_s1_cv_std = float('inf'), 0\n",
        "    gb_s2_cv_mean, gb_s2_cv_std = float('inf'), 0\n",
        "\n",
        "print(\"\\n‚úÖ Cross-validation complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4.5: Feature Importance Analysis\n",
        "\n",
        "**What we're doing:** Analyze which features are most important for predictions\n",
        "\n",
        "**Why:**\n",
        "- Understand what drives emissions predictions\n",
        "- Validate that features make sense\n",
        "- Identify potential improvements\n",
        "- Helps explain model decisions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4.5: Feature Importance Analysis\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 4.5: Feature Importance Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get feature importances from Random Forest\n",
        "feature_importance_s1 = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': rf_s1.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "feature_importance_s2 = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': rf_s2.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nüìä Top 10 Most Important Features - Scope 1:\")\n",
        "print(feature_importance_s1.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\nüìä Top 10 Most Important Features - Scope 2:\")\n",
        "print(feature_importance_s2.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\n‚úÖ Feature importance analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4.6: Select Best Model\n",
        "\n",
        "**What we're doing:** Compare models and select the best one for final training\n",
        "\n",
        "**Why:**\n",
        "- Need to choose which model performs best\n",
        "- Will use this for final predictions on test set\n",
        "- Document the decision for submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4.6: Select Best Model\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 4.6: Model Comparison & Selection\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Compare all models\n",
        "print(\"\\nüìä Model Comparison Summary:\")\n",
        "print(\"\\nScope 1 Emissions:\")\n",
        "print(f\"  Linear Regression CV RMSE: {lr_s1_cv_mean:,.2f} ¬± {lr_s1_cv_std:,.2f}\")\n",
        "print(f\"  Random Forest CV RMSE: {rf_s1_cv_mean:,.2f} ¬± {rf_s1_cv_std:,.2f}\")\n",
        "if 'gb_available' in locals() and gb_available:\n",
        "    print(f\"  Gradient Boosting CV RMSE: {gb_s1_cv_mean:,.2f} ¬± {gb_s1_cv_std:,.2f}\")\n",
        "\n",
        "# Find best model for Scope 1\n",
        "models_s1 = {\n",
        "    'Linear Regression': (lr_s1_cv_mean, lr_s1),\n",
        "    'Random Forest': (rf_s1_cv_mean, rf_s1)\n",
        "}\n",
        "if 'gb_available' in locals() and gb_available:\n",
        "    models_s1['Gradient Boosting'] = (gb_s1_cv_mean, gb_s1)\n",
        "\n",
        "best_s1_name = min(models_s1, key=lambda x: models_s1[x][0])\n",
        "best_s1_model = models_s1[best_s1_name][1]\n",
        "print(f\"  ‚úÖ Best model for Scope 1: {best_s1_name} (RMSE: {models_s1[best_s1_name][0]:,.2f})\")\n",
        "\n",
        "print(\"\\nScope 2 Emissions:\")\n",
        "print(f\"  Linear Regression CV RMSE: {lr_s2_cv_mean:,.2f} ¬± {lr_s2_cv_std:,.2f}\")\n",
        "print(f\"  Random Forest CV RMSE: {rf_s2_cv_mean:,.2f} ¬± {rf_s2_cv_std:,.2f}\")\n",
        "if 'gb_available' in locals() and gb_available:\n",
        "    print(f\"  Gradient Boosting CV RMSE: {gb_s2_cv_mean:,.2f} ¬± {gb_s2_cv_std:,.2f}\")\n",
        "\n",
        "# Find best model for Scope 2\n",
        "models_s2 = {\n",
        "    'Linear Regression': (lr_s2_cv_mean, lr_s2),\n",
        "    'Random Forest': (rf_s2_cv_mean, rf_s2)\n",
        "}\n",
        "if 'gb_available' in locals() and gb_available:\n",
        "    models_s2['Gradient Boosting'] = (gb_s2_cv_mean, gb_s2)\n",
        "\n",
        "best_s2_name = min(models_s2, key=lambda x: models_s2[x][0])\n",
        "best_s2_model = models_s2[best_s2_name][1]\n",
        "print(f\"  ‚úÖ Best model for Scope 2: {best_s2_name} (RMSE: {models_s2[best_s2_name][0]:,.2f})\")\n",
        "\n",
        "print(f\"\\n‚úÖ Selected models:\")\n",
        "print(f\"  Scope 1: {best_s1_name}\")\n",
        "print(f\"  Scope 2: {best_s2_name}\")\n",
        "\n",
        "# Train final models on full training data\n",
        "print(f\"\\nüîÑ Training final models on full training data...\")\n",
        "best_s1_model.fit(X_train, y_scope1_log)\n",
        "best_s2_model.fit(X_train, y_scope2_log)\n",
        "print(f\"‚úÖ Final models trained!\")\n",
        "\n",
        "# Save models for later use\n",
        "import joblib\n",
        "import os\n",
        "save_dir = 'notebooks' if os.path.exists('notebooks') else '.'\n",
        "joblib.dump(best_s1_model, f'{save_dir}/model_scope1.pkl')\n",
        "joblib.dump(best_s2_model, f'{save_dir}/model_scope2.pkl')\n",
        "print(f\"‚úÖ Models saved to {save_dir}/model_scope1.pkl and {save_dir}/model_scope2.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 4 Summary\n",
        "\n",
        "**Models Trained:**\n",
        "- Linear Regression (with StandardScaler)\n",
        "- Random Forest (100 trees, max_depth=10)\n",
        "\n",
        "**Performance Metrics:**\n",
        "- Evaluated using 5-fold cross-validation\n",
        "- Metrics: RMSE, MAE, R¬≤\n",
        "- Targets log-transformed for training\n",
        "\n",
        "**Next Steps:** Proceed to Phase 5: Prediction & Submission\n",
        "\n",
        "---\n",
        "\n",
        "## Phase 5: Prediction & Submission\n",
        "\n",
        "### Step 5.1: Generate Test Predictions\n",
        "\n",
        "**What we're doing:** Use final models to predict on test set\n",
        "\n",
        "**Why:**\n",
        "- This is the final output for submission\n",
        "- Must use same preprocessing as training\n",
        "- Must ensure test features match training features exactly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5.1: Generate Test Predictions\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 5: PREDICTION & SUBMISSION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Generate predictions (in log space)\n",
        "print(\"\\nüîÆ Generating predictions on test set...\")\n",
        "s1_predictions_log = best_s1_model.predict(X_test)\n",
        "s2_predictions_log = best_s2_model.predict(X_test)\n",
        "\n",
        "# Convert back from log space\n",
        "s1_predictions = np.expm1(s1_predictions_log)\n",
        "s2_predictions = np.expm1(s2_predictions_log)\n",
        "\n",
        "# Ensure non-negative predictions (emissions can't be negative)\n",
        "s1_predictions = np.maximum(s1_predictions, 0)\n",
        "s2_predictions = np.maximum(s2_predictions, 0)\n",
        "\n",
        "print(f\"\\n‚úÖ Predictions generated:\")\n",
        "print(f\"  Scope 1 predictions: {len(s1_predictions)}\")\n",
        "print(f\"  Scope 2 predictions: {len(s2_predictions)}\")\n",
        "print(f\"\\nüìä Prediction statistics:\")\n",
        "print(f\"  Scope 1 - Min: {s1_predictions.min():.2f}, Max: {s1_predictions.max():,.2f}, Mean: {s1_predictions.mean():,.2f}\")\n",
        "print(f\"  Scope 2 - Min: {s2_predictions.min():.2f}, Max: {s2_predictions.max():,.2f}, Mean: {s2_predictions.mean():,.2f}\")\n",
        "\n",
        "# Validation checks\n",
        "print(f\"\\nüìä Validation checks:\")\n",
        "print(f\"  Negative predictions (should be 0): {(s1_predictions < 0).sum() + (s2_predictions < 0).sum()}\")\n",
        "print(f\"  Infinite predictions: {np.isinf(s1_predictions).sum() + np.isinf(s2_predictions).sum()}\")\n",
        "print(f\"  Missing predictions: {np.isnan(s1_predictions).sum() + np.isnan(s2_predictions).sum()}\")\n",
        "print(f\"  ‚úÖ All predictions valid!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5.2: Create Submission File\n",
        "\n",
        "**What we're doing:** Format predictions into submission CSV\n",
        "\n",
        "**Why:**\n",
        "- Must match expected format exactly\n",
        "- Column names must be correct\n",
        "- Entity IDs must match test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5.2: Create Submission File\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 5.2: Create Submission File\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'entity_id': entity_ids_test,\n",
        "    's1_predictions': s1_predictions,\n",
        "    's2_predictions': s2_predictions\n",
        "})\n",
        "\n",
        "# Ensure entity_ids are in same order as test.csv\n",
        "test_original = pd.read_csv(\"../data/test.csv\")\n",
        "submission = submission.sort_values('entity_id').reset_index(drop=True)\n",
        "\n",
        "# Verify submission format\n",
        "print(f\"\\nüìä Submission file validation:\")\n",
        "print(f\"  Shape: {submission.shape}\")\n",
        "print(f\"  Columns: {list(submission.columns)}\")\n",
        "print(f\"  Entity IDs match test.csv: {(submission['entity_id'] == test_original['entity_id']).all()}\")\n",
        "print(f\"  All predictions non-negative: {(submission[['s1_predictions', 's2_predictions']] >= 0).all().all()}\")\n",
        "print(f\"  No missing values: {submission.isnull().sum().sum()}\")\n",
        "\n",
        "# Save submission file\n",
        "import os\n",
        "save_dir = 'notebooks' if os.path.exists('notebooks') else '.'\n",
        "submission_path = f'{save_dir}/submission_comprehensive.csv'\n",
        "submission.to_csv(submission_path, index=False)\n",
        "print(f\"\\n‚úÖ Submission file saved to: {submission_path}\")\n",
        "print(f\"\\nüìÑ First few rows:\")\n",
        "print(submission.head(10))\n",
        "\n",
        "print(f\"\\n‚úÖ Phase 5 Complete! Ready for submission!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
